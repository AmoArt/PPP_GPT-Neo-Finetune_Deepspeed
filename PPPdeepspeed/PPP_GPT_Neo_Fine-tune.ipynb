{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefe4b59",
   "metadata": {},
   "source": [
    "## First we must install Pytorch along all the CUDA requiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6825812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04081ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting happytransformer\n",
      "  Using cached happytransformer-2.4.1-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from transformers) (1.21.2)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from transformers) (4.8.2)\n",
      "Collecting requests\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting datasets>=1.6.0\n",
      "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: torch>=1.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from happytransformer) (1.10.2)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Using cached fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Using cached pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (21.4.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Using cached asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from pandas->datasets>=1.6.0->happytransformer) (2.8.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.6.0->happytransformer) (1.16.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: multidict, idna, frozenlist, yarl, urllib3, charset-normalizer, asynctest, async-timeout, aiosignal, requests, regex, pyyaml, pytz, joblib, fsspec, filelock, dill, click, aiohttp, xxhash, tokenizers, sacremoses, responses, pyarrow, pandas, multiprocess, huggingface-hub, transformers, sentencepiece, protobuf, datasets, happytransformer\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 charset-normalizer-2.0.12 click-8.0.4 datasets-1.18.4 dill-0.3.4 filelock-3.6.0 frozenlist-1.3.0 fsspec-2022.2.0 happytransformer-2.4.1 huggingface-hub-0.4.0 idna-3.3 joblib-1.1.0 multidict-6.0.2 multiprocess-0.70.12.2 pandas-1.3.5 protobuf-3.19.4 pyarrow-7.0.0 pytz-2021.3 pyyaml-6.0 regex-2022.3.2 requests-2.27.1 responses-0.18.0 sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.17.0 urllib3-1.26.8 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers happytransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a45d21",
   "metadata": {},
   "source": [
    "## (assuming you only have one gpu, this line of code directs the code to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85ec83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7db7e",
   "metadata": {},
   "source": [
    "## Now we move one to Step 2: Downloading Deep Learning from Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be6acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DeepSpeed' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/DeepSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc2a9f",
   "metadata": {},
   "source": [
    "## We are now going to run ls to see our folder structure, we should now see DeepSpeed, we are going to cd into that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39432859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpeed  GPT_Neo_Fine-tune.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f239c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user02/Desktop/PPPdeepspeed/DeepSpeed\n"
     ]
    }
   ],
   "source": [
    "%cd DeepSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059634e1",
   "metadata": {},
   "source": [
    "## If we run ls again, we will see the contents of the DeepSpeed repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b492a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure\t\t    deepspeed\t\tLICENSE\t\t SECURITY.md\r\n",
      "bin\t\t    deepspeed.egg-info\tMANIFEST.in\t setup.cfg\r\n",
      "build\t\t    DeepSpeedExamples\tMANIFEST_win.in  setup.py\r\n",
      "CODE_OF_CONDUCT.md  dist\t\top_builder\t tests\r\n",
      "CODEOWNERS\t    docker\t\tREADME.md\t version.txt\r\n",
      "CONTRIBUTING.md     docs\t\trelease\r\n",
      "csrc\t\t    install.sh\t\trequirements\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9f586",
   "metadata": {},
   "source": [
    "## We are now going to install DeepSpeed from source using a flag to insure that all the needed ops are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5d7603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hostfile exists at /job/hostfile, installing locally\n",
      "Building deepspeed wheel\n",
      "DS_BUILD_OPS=0\n",
      "Install Ops={'cpu_adam': False, 'cpu_adagrad': False, 'fused_adam': False, 'fused_lamb': False, 'sparse_attn': False, 'transformer': False, 'stochastic_transformer': False, 'async_io': False, 'utils': False, 'quantizer': False, 'transformer_inference': False}\n",
      "version=0.6.1+097efeb, git_hash=097efeb, git_branch=master\n",
      "install_requires=['hjson', 'ninja', 'numpy', 'packaging', 'psutil', 'py-cpuinfo', 'torch', 'tqdm', 'triton==1.0.0']\n",
      "compatible_ops={'cpu_adam': True, 'cpu_adagrad': True, 'fused_adam': True, 'fused_lamb': True, 'sparse_attn': True, 'transformer': True, 'stochastic_transformer': True, 'async_io': True, 'utils': True, 'quantizer': True, 'transformer_inference': True}\n",
      "ext_modules=[]\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "copying deepspeed/git_version_info_installed.py -> build/lib/deepspeed\n",
      "running egg_info\n",
      "writing deepspeed.egg-info/PKG-INFO\n",
      "writing dependency_links to deepspeed.egg-info/dependency_links.txt\n",
      "writing entry points to deepspeed.egg-info/entry_points.txt\n",
      "writing requirements to deepspeed.egg-info/requires.txt\n",
      "writing top-level names to deepspeed.egg-info/top_level.txt\n",
      "reading manifest file 'deepspeed.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "warning: no files found matching '*.hip' under directory 'deepspeed'\n",
      "warning: no files found matching '*.cc' under directory 'deepspeed'\n",
      "warning: no files found matching '*.tr' under directory 'csrc'\n",
      "warning: no files found matching '*.cc' under directory 'csrc'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'deepspeed.egg-info/SOURCES.txt'\n",
      "running build_scripts\n",
      "copying and adjusting bin/deepspeed -> build/scripts-3.7\n",
      "copying and adjusting bin/deepspeed.pt -> build/scripts-3.7\n",
      "copying and adjusting bin/ds -> build/scripts-3.7\n",
      "copying bin/ds_ssh -> build/scripts-3.7\n",
      "copying and adjusting bin/ds_report -> build/scripts-3.7\n",
      "copying and adjusting bin/ds_elastic -> build/scripts-3.7\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/wheel\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/base_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/cost_model.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/index_based_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/model_based_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/tuner/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner\n",
      "copying build/lib/deepspeed/autotuning/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "copying build/lib/deepspeed/autotuning/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates\n",
      "copying build/lib/deepspeed/autotuning/config_templates/template_zero3.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates\n",
      "copying build/lib/deepspeed/autotuning/config_templates/template_zero2.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates\n",
      "copying build/lib/deepspeed/autotuning/config_templates/template_zero1.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates\n",
      "copying build/lib/deepspeed/autotuning/config_templates/template_zero0.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates\n",
      "copying build/lib/deepspeed/autotuning/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "copying build/lib/deepspeed/autotuning/autotuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "copying build/lib/deepspeed/autotuning/scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "copying build/lib/deepspeed/autotuning/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning\n",
      "copying build/lib/deepspeed/git_version_info_installed.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/inference\n",
      "copying build/lib/deepspeed/inference/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference\n",
      "copying build/lib/deepspeed/inference/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/quantize.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/dataloader.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/aio_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/async_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/pipelined_optimizer_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/partitioned_optimizer_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/partitioned_param_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/optimizer_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "copying build/lib/deepspeed/runtime/swap_tensor/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline\n",
      "copying build/lib/deepspeed/runtime/data_pipeline/curriculum_scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline\n",
      "copying build/lib/deepspeed/runtime/data_pipeline/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline\n",
      "copying build/lib/deepspeed/runtime/sparse_tensor.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing\n",
      "copying build/lib/deepspeed/runtime/activation_checkpointing/checkpointing.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing\n",
      "copying build/lib/deepspeed/runtime/activation_checkpointing/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing\n",
      "copying build/lib/deepspeed/runtime/activation_checkpointing/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing\n",
      "copying build/lib/deepspeed/runtime/lr_schedules.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm\n",
      "copying build/lib/deepspeed/runtime/comm/coalesced_collectives.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm\n",
      "copying build/lib/deepspeed/runtime/comm/mpi.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm\n",
      "copying build/lib/deepspeed/runtime/comm/nccl.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm\n",
      "copying build/lib/deepspeed/runtime/comm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm\n",
      "copying build/lib/deepspeed/runtime/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression\n",
      "copying build/lib/deepspeed/runtime/compression/cupy.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression\n",
      "copying build/lib/deepspeed/runtime/compression/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/linear.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/partition_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/test.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/stage3.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/tiling.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/offload_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/offload_constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/stage_1_and_2.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/contiguous_memory_allocator.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/zero/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero\n",
      "copying build/lib/deepspeed/runtime/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16\n",
      "copying build/lib/deepspeed/runtime/fp16/unfused_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16\n",
      "copying build/lib/deepspeed/runtime/fp16/loss_scaler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16\n",
      "copying build/lib/deepspeed/runtime/fp16/fused_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit\n",
      "copying build/lib/deepspeed/runtime/fp16/onebit/lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit\n",
      "copying build/lib/deepspeed/runtime/fp16/onebit/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit\n",
      "copying build/lib/deepspeed/runtime/fp16/onebit/adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit\n",
      "copying build/lib/deepspeed/runtime/fp16/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16\n",
      "copying build/lib/deepspeed/runtime/config_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/weight_quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/progressive_layer_drop.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/module.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/p2p.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/topology.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/schedule.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/pipe/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe\n",
      "copying build/lib/deepspeed/runtime/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/state_dict_factory.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "copying build/lib/deepspeed/runtime/eigenvalue.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer\n",
      "copying build/lib/deepspeed/ops/transformer/transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference\n",
      "copying build/lib/deepspeed/ops/transformer/inference/transformer_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference\n",
      "copying build/lib/deepspeed/ops/transformer/inference/moe_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference\n",
      "copying build/lib/deepspeed/ops/transformer/inference/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference\n",
      "copying build/lib/deepspeed/ops/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/adam\n",
      "copying build/lib/deepspeed/ops/adam/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam\n",
      "copying build/lib/deepspeed/ops/adam/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam\n",
      "copying build/lib/deepspeed/ops/adam/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam\n",
      "copying build/lib/deepspeed/ops/adam/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/gelu_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/normalize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/includes/context.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/includes/cublas_wrappers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/inference/includes/custom_cuda_layers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/dropout_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/cublas_wrappers.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/general_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/normalize_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/transform_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/softmax_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "copying build/lib/deepspeed/ops/csrc/transformer/ds_transformer_cuda.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam\n",
      "copying build/lib/deepspeed/ops/csrc/adam/multi_tensor_apply.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam\n",
      "copying build/lib/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam\n",
      "copying build/lib/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam\n",
      "copying build/lib/deepspeed/ops/csrc/adam/cpu_adam.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/compat.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/context.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/cublas_wrappers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/custom_cuda_layers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/Timer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/dropout.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/feed_forward.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/gelu.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/normalize_layer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/gemm_test.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/ds_transformer_cuda.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/softmax.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/cpu_adam.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/StopWatch.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/strided_batch_gemm.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes/patch\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes/patch/hip\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes/patch/hip/hcc_detail\n",
      "copying build/lib/deepspeed/ops/csrc/includes/patch/hip/hcc_detail/hip_cooperative_groups.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes/patch/hip/hcc_detail\n",
      "copying build/lib/deepspeed/ops/csrc/includes/patch/hip/hcc_detail/hip_cooperative_groups_helper.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes/patch/hip/hcc_detail\n",
      "copying build/lib/deepspeed/ops/csrc/includes/cpu_adagrad.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/general_kernels.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/type_shim.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/simd.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "copying build/lib/deepspeed/ops/csrc/includes/quantizer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/utils\n",
      "copying build/lib/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/utils\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/common\n",
      "copying build/lib/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/common\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization\n",
      "copying build/lib/deepspeed/ops/csrc/quantization/quantizer.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization\n",
      "copying build/lib/deepspeed/ops/csrc/quantization/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_test\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_test/single_process_config.json -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_test\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/py_ds_aio.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "copying build/lib/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_types.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_common.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_common.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "copying build/lib/deepspeed/ops/csrc/aio/common/deepspeed_aio_types.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adagrad\n",
      "copying build/lib/deepspeed/ops/csrc/adagrad/cpu_adagrad.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adagrad\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb\n",
      "copying build/lib/deepspeed/ops/csrc/lamb/fused_lamb_cuda_kernel.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb\n",
      "copying build/lib/deepspeed/ops/csrc/lamb/fused_lamb_cuda.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/sparse_attention\n",
      "copying build/lib/deepspeed/ops/csrc/sparse_attention/utils.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/sparse_attention\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer\n",
      "copying build/lib/deepspeed/ops/quantizer/quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer\n",
      "copying build/lib/deepspeed/ops/quantizer/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/aio\n",
      "copying build/lib/deepspeed/ops/aio/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/aio\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad\n",
      "copying build/lib/deepspeed/ops/adagrad/cpu_adagrad.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad\n",
      "copying build/lib/deepspeed/ops/adagrad/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb\n",
      "copying build/lib/deepspeed/ops/lamb/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb\n",
      "copying build/lib/deepspeed/ops/lamb/fused_lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb\n",
      "copying build/lib/deepspeed/ops/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/stochastic_transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/transformer_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/async_io.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/cpu_adagrad.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/sparse_attn.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "copying build/lib/deepspeed/ops/op_builder/fused_lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/softmax.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/bert_sparse_self_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/matmul.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/sparse_self_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/sparsity_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/sparse_attention_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "copying build/lib/deepspeed/ops/sparse_attention/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc\n",
      "copying build/lib/deepspeed/ops/sparse_attention/trsrc/softmax_bwd.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc\n",
      "copying build/lib/deepspeed/ops/sparse_attention/trsrc/softmax_fwd.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc\n",
      "copying build/lib/deepspeed/ops/sparse_attention/trsrc/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc\n",
      "copying build/lib/deepspeed/ops/sparse_attention/trsrc/matmul.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/nvtx.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/zero_to_fp32.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/groups.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/distributed.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/timer.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/exceptions.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/logging.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/utils/debug.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils\n",
      "copying build/lib/deepspeed/env_report.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/checkpoint\n",
      "copying build/lib/deepspeed/checkpoint/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint\n",
      "copying build/lib/deepspeed/checkpoint/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint\n",
      "copying build/lib/deepspeed/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "copying build/lib/deepspeed/launcher/multinode_runner.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "copying build/lib/deepspeed/launcher/runner.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "copying build/lib/deepspeed/launcher/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "copying build/lib/deepspeed/launcher/launch.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "copying build/lib/deepspeed/launcher/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/elasticity\n",
      "copying build/lib/deepspeed/elasticity/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity\n",
      "copying build/lib/deepspeed/elasticity/elasticity.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity\n",
      "copying build/lib/deepspeed/elasticity/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity\n",
      "copying build/lib/deepspeed/elasticity/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/profiling\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler\n",
      "copying build/lib/deepspeed/profiling/flops_profiler/profiler.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler\n",
      "copying build/lib/deepspeed/profiling/flops_profiler/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler\n",
      "copying build/lib/deepspeed/profiling/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling\n",
      "copying build/lib/deepspeed/profiling/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling\n",
      "copying build/lib/deepspeed/profiling/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/pipe\n",
      "copying build/lib/deepspeed/pipe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/pipe\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/moe/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/moe/sharded_moe.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/moe/layer.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/moe/experts.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/moe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe\n",
      "copying build/lib/deepspeed/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/module_inject/module_quantize.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/module_inject/inject.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/module_inject/replace_policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/module_inject/replace_module.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/module_inject/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject\n",
      "copying build/lib/deepspeed/git_version_info.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
      "running install_egg_info\n",
      "Copying deepspeed.egg-info to build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb-py3.7.egg-info\n",
      "running install_scripts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/ds_ssh -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/deepspeed.pt -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/ds -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/deepspeed -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/ds_elastic -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "copying build/scripts-3.7/ds_report -> build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/ds_ssh to 775\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/deepspeed.pt to 775\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/ds to 775\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/deepspeed to 775\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/ds_elastic to 775\n",
      "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.data/scripts/ds_report to 775\n",
      "adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
      "creating build/bdist.linux-x86_64/wheel/deepspeed-0.6.1+097efeb.dist-info/WHEEL\n",
      "creating 'dist/deepspeed-0.6.1+097efeb-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'deepspeed/__init__.py'\n",
      "adding 'deepspeed/constants.py'\n",
      "adding 'deepspeed/env_report.py'\n",
      "adding 'deepspeed/git_version_info.py'\n",
      "adding 'deepspeed/git_version_info_installed.py'\n",
      "adding 'deepspeed/autotuning/__init__.py'\n",
      "adding 'deepspeed/autotuning/autotuner.py'\n",
      "adding 'deepspeed/autotuning/config.py'\n",
      "adding 'deepspeed/autotuning/constants.py'\n",
      "adding 'deepspeed/autotuning/scheduler.py'\n",
      "adding 'deepspeed/autotuning/utils.py'\n",
      "adding 'deepspeed/autotuning/config_templates/template_zero0.json'\n",
      "adding 'deepspeed/autotuning/config_templates/template_zero1.json'\n",
      "adding 'deepspeed/autotuning/config_templates/template_zero2.json'\n",
      "adding 'deepspeed/autotuning/config_templates/template_zero3.json'\n",
      "adding 'deepspeed/autotuning/tuner/__init__.py'\n",
      "adding 'deepspeed/autotuning/tuner/base_tuner.py'\n",
      "adding 'deepspeed/autotuning/tuner/cost_model.py'\n",
      "adding 'deepspeed/autotuning/tuner/index_based_tuner.py'\n",
      "adding 'deepspeed/autotuning/tuner/model_based_tuner.py'\n",
      "adding 'deepspeed/autotuning/tuner/utils.py'\n",
      "adding 'deepspeed/checkpoint/__init__.py'\n",
      "adding 'deepspeed/checkpoint/constants.py'\n",
      "adding 'deepspeed/elasticity/__init__.py'\n",
      "adding 'deepspeed/elasticity/config.py'\n",
      "adding 'deepspeed/elasticity/constants.py'\n",
      "adding 'deepspeed/elasticity/elasticity.py'\n",
      "adding 'deepspeed/inference/__init__.py'\n",
      "adding 'deepspeed/inference/engine.py'\n",
      "adding 'deepspeed/launcher/__init__.py'\n",
      "adding 'deepspeed/launcher/constants.py'\n",
      "adding 'deepspeed/launcher/launch.py'\n",
      "adding 'deepspeed/launcher/multinode_runner.py'\n",
      "adding 'deepspeed/launcher/runner.py'\n",
      "adding 'deepspeed/module_inject/__init__.py'\n",
      "adding 'deepspeed/module_inject/inject.py'\n",
      "adding 'deepspeed/module_inject/module_quantize.py'\n",
      "adding 'deepspeed/module_inject/replace_module.py'\n",
      "adding 'deepspeed/module_inject/replace_policy.py'\n",
      "adding 'deepspeed/moe/__init__.py'\n",
      "adding 'deepspeed/moe/experts.py'\n",
      "adding 'deepspeed/moe/layer.py'\n",
      "adding 'deepspeed/moe/sharded_moe.py'\n",
      "adding 'deepspeed/moe/utils.py'\n",
      "adding 'deepspeed/ops/__init__.py'\n",
      "adding 'deepspeed/ops/adagrad/__init__.py'\n",
      "adding 'deepspeed/ops/adagrad/cpu_adagrad.py'\n",
      "adding 'deepspeed/ops/adam/__init__.py'\n",
      "adding 'deepspeed/ops/adam/cpu_adam.py'\n",
      "adding 'deepspeed/ops/adam/fused_adam.py'\n",
      "adding 'deepspeed/ops/adam/multi_tensor_apply.py'\n",
      "adding 'deepspeed/ops/aio/__init__.py'\n",
      "adding 'deepspeed/ops/csrc/adagrad/cpu_adagrad.cpp'\n",
      "adding 'deepspeed/ops/csrc/adam/cpu_adam.cpp'\n",
      "adding 'deepspeed/ops/csrc/adam/fused_adam_frontend.cpp'\n",
      "adding 'deepspeed/ops/csrc/adam/multi_tensor_adam.cu'\n",
      "adding 'deepspeed/ops/csrc/adam/multi_tensor_apply.cuh'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_common.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_common.h'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_types.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_types.h'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.h'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.h'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.h'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.h'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.h'\n",
      "adding 'deepspeed/ops/csrc/aio/py_lib/py_ds_aio.cpp'\n",
      "adding 'deepspeed/ops/csrc/aio/py_test/single_process_config.json'\n",
      "adding 'deepspeed/ops/csrc/common/custom_cuda_kernel.cu'\n",
      "adding 'deepspeed/ops/csrc/includes/StopWatch.h'\n",
      "adding 'deepspeed/ops/csrc/includes/Timer.h'\n",
      "adding 'deepspeed/ops/csrc/includes/compat.h'\n",
      "adding 'deepspeed/ops/csrc/includes/context.h'\n",
      "adding 'deepspeed/ops/csrc/includes/cpu_adagrad.h'\n",
      "adding 'deepspeed/ops/csrc/includes/cpu_adam.h'\n",
      "adding 'deepspeed/ops/csrc/includes/cublas_wrappers.h'\n",
      "adding 'deepspeed/ops/csrc/includes/custom_cuda_layers.h'\n",
      "adding 'deepspeed/ops/csrc/includes/dropout.h'\n",
      "adding 'deepspeed/ops/csrc/includes/ds_transformer_cuda.h'\n",
      "adding 'deepspeed/ops/csrc/includes/feed_forward.h'\n",
      "adding 'deepspeed/ops/csrc/includes/gelu.h'\n",
      "adding 'deepspeed/ops/csrc/includes/gemm_test.h'\n",
      "adding 'deepspeed/ops/csrc/includes/general_kernels.h'\n",
      "adding 'deepspeed/ops/csrc/includes/normalize_layer.h'\n",
      "adding 'deepspeed/ops/csrc/includes/quantizer.h'\n",
      "adding 'deepspeed/ops/csrc/includes/simd.h'\n",
      "adding 'deepspeed/ops/csrc/includes/softmax.h'\n",
      "adding 'deepspeed/ops/csrc/includes/strided_batch_gemm.h'\n",
      "adding 'deepspeed/ops/csrc/includes/type_shim.h'\n",
      "adding 'deepspeed/ops/csrc/includes/patch/hip/hcc_detail/hip_cooperative_groups.h'\n",
      "adding 'deepspeed/ops/csrc/includes/patch/hip/hcc_detail/hip_cooperative_groups_helper.h'\n",
      "adding 'deepspeed/ops/csrc/lamb/fused_lamb_cuda.cpp'\n",
      "adding 'deepspeed/ops/csrc/lamb/fused_lamb_cuda_kernel.cu'\n",
      "adding 'deepspeed/ops/csrc/quantization/pt_binding.cpp'\n",
      "adding 'deepspeed/ops/csrc/quantization/quantizer.cu'\n",
      "adding 'deepspeed/ops/csrc/sparse_attention/utils.cpp'\n",
      "adding 'deepspeed/ops/csrc/transformer/cublas_wrappers.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/dropout_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/ds_transformer_cuda.cpp'\n",
      "adding 'deepspeed/ops/csrc/transformer/gelu_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/general_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/normalize_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/softmax_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/transform_kernels.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/normalize.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/includes/context.h'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/includes/cublas_wrappers.h'\n",
      "adding 'deepspeed/ops/csrc/transformer/inference/includes/custom_cuda_layers.h'\n",
      "adding 'deepspeed/ops/csrc/utils/flatten_unflatten.cpp'\n",
      "adding 'deepspeed/ops/lamb/__init__.py'\n",
      "adding 'deepspeed/ops/lamb/fused_lamb.py'\n",
      "adding 'deepspeed/ops/op_builder/__init__.py'\n",
      "adding 'deepspeed/ops/op_builder/async_io.py'\n",
      "adding 'deepspeed/ops/op_builder/builder.py'\n",
      "adding 'deepspeed/ops/op_builder/cpu_adagrad.py'\n",
      "adding 'deepspeed/ops/op_builder/cpu_adam.py'\n",
      "adding 'deepspeed/ops/op_builder/fused_adam.py'\n",
      "adding 'deepspeed/ops/op_builder/fused_lamb.py'\n",
      "adding 'deepspeed/ops/op_builder/quantizer.py'\n",
      "adding 'deepspeed/ops/op_builder/sparse_attn.py'\n",
      "adding 'deepspeed/ops/op_builder/stochastic_transformer.py'\n",
      "adding 'deepspeed/ops/op_builder/transformer.py'\n",
      "adding 'deepspeed/ops/op_builder/transformer_inference.py'\n",
      "adding 'deepspeed/ops/op_builder/utils.py'\n",
      "adding 'deepspeed/ops/quantizer/__init__.py'\n",
      "adding 'deepspeed/ops/quantizer/quantizer.py'\n",
      "adding 'deepspeed/ops/sparse_attention/__init__.py'\n",
      "adding 'deepspeed/ops/sparse_attention/bert_sparse_self_attention.py'\n",
      "adding 'deepspeed/ops/sparse_attention/matmul.py'\n",
      "adding 'deepspeed/ops/sparse_attention/softmax.py'\n",
      "adding 'deepspeed/ops/sparse_attention/sparse_attention_utils.py'\n",
      "adding 'deepspeed/ops/sparse_attention/sparse_self_attention.py'\n",
      "adding 'deepspeed/ops/sparse_attention/sparsity_config.py'\n",
      "adding 'deepspeed/ops/sparse_attention/trsrc/__init__.py'\n",
      "adding 'deepspeed/ops/sparse_attention/trsrc/matmul.tr'\n",
      "adding 'deepspeed/ops/sparse_attention/trsrc/softmax_bwd.tr'\n",
      "adding 'deepspeed/ops/sparse_attention/trsrc/softmax_fwd.tr'\n",
      "adding 'deepspeed/ops/transformer/__init__.py'\n",
      "adding 'deepspeed/ops/transformer/transformer.py'\n",
      "adding 'deepspeed/ops/transformer/inference/__init__.py'\n",
      "adding 'deepspeed/ops/transformer/inference/moe_inference.py'\n",
      "adding 'deepspeed/ops/transformer/inference/transformer_inference.py'\n",
      "adding 'deepspeed/pipe/__init__.py'\n",
      "adding 'deepspeed/profiling/__init__.py'\n",
      "adding 'deepspeed/profiling/config.py'\n",
      "adding 'deepspeed/profiling/constants.py'\n",
      "adding 'deepspeed/profiling/flops_profiler/__init__.py'\n",
      "adding 'deepspeed/profiling/flops_profiler/profiler.py'\n",
      "adding 'deepspeed/runtime/__init__.py'\n",
      "adding 'deepspeed/runtime/config.py'\n",
      "adding 'deepspeed/runtime/config_utils.py'\n",
      "adding 'deepspeed/runtime/constants.py'\n",
      "adding 'deepspeed/runtime/dataloader.py'\n",
      "adding 'deepspeed/runtime/eigenvalue.py'\n",
      "adding 'deepspeed/runtime/engine.py'\n",
      "adding 'deepspeed/runtime/lr_schedules.py'\n",
      "adding 'deepspeed/runtime/progressive_layer_drop.py'\n",
      "adding 'deepspeed/runtime/quantize.py'\n",
      "adding 'deepspeed/runtime/sparse_tensor.py'\n",
      "adding 'deepspeed/runtime/state_dict_factory.py'\n",
      "adding 'deepspeed/runtime/utils.py'\n",
      "adding 'deepspeed/runtime/weight_quantizer.py'\n",
      "adding 'deepspeed/runtime/activation_checkpointing/__init__.py'\n",
      "adding 'deepspeed/runtime/activation_checkpointing/checkpointing.py'\n",
      "adding 'deepspeed/runtime/activation_checkpointing/config.py'\n",
      "adding 'deepspeed/runtime/comm/__init__.py'\n",
      "adding 'deepspeed/runtime/comm/coalesced_collectives.py'\n",
      "adding 'deepspeed/runtime/comm/mpi.py'\n",
      "adding 'deepspeed/runtime/comm/nccl.py'\n",
      "adding 'deepspeed/runtime/compression/__init__.py'\n",
      "adding 'deepspeed/runtime/compression/cupy.py'\n",
      "adding 'deepspeed/runtime/data_pipeline/__init__.py'\n",
      "adding 'deepspeed/runtime/data_pipeline/curriculum_scheduler.py'\n",
      "adding 'deepspeed/runtime/fp16/__init__.py'\n",
      "adding 'deepspeed/runtime/fp16/fused_optimizer.py'\n",
      "adding 'deepspeed/runtime/fp16/loss_scaler.py'\n",
      "adding 'deepspeed/runtime/fp16/unfused_optimizer.py'\n",
      "adding 'deepspeed/runtime/fp16/onebit/__init__.py'\n",
      "adding 'deepspeed/runtime/fp16/onebit/adam.py'\n",
      "adding 'deepspeed/runtime/fp16/onebit/lamb.py'\n",
      "adding 'deepspeed/runtime/pipe/__init__.py'\n",
      "adding 'deepspeed/runtime/pipe/engine.py'\n",
      "adding 'deepspeed/runtime/pipe/module.py'\n",
      "adding 'deepspeed/runtime/pipe/p2p.py'\n",
      "adding 'deepspeed/runtime/pipe/schedule.py'\n",
      "adding 'deepspeed/runtime/pipe/topology.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/__init__.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/aio_config.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/async_swapper.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/constants.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/optimizer_utils.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/partitioned_optimizer_swapper.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/partitioned_param_swapper.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/pipelined_optimizer_swapper.py'\n",
      "adding 'deepspeed/runtime/swap_tensor/utils.py'\n",
      "adding 'deepspeed/runtime/zero/__init__.py'\n",
      "adding 'deepspeed/runtime/zero/config.py'\n",
      "adding 'deepspeed/runtime/zero/constants.py'\n",
      "adding 'deepspeed/runtime/zero/contiguous_memory_allocator.py'\n",
      "adding 'deepspeed/runtime/zero/linear.py'\n",
      "adding 'deepspeed/runtime/zero/offload_config.py'\n",
      "adding 'deepspeed/runtime/zero/offload_constants.py'\n",
      "adding 'deepspeed/runtime/zero/partition_parameters.py'\n",
      "adding 'deepspeed/runtime/zero/stage3.py'\n",
      "adding 'deepspeed/runtime/zero/stage_1_and_2.py'\n",
      "adding 'deepspeed/runtime/zero/test.py'\n",
      "adding 'deepspeed/runtime/zero/tiling.py'\n",
      "adding 'deepspeed/runtime/zero/utils.py'\n",
      "adding 'deepspeed/utils/__init__.py'\n",
      "adding 'deepspeed/utils/debug.py'\n",
      "adding 'deepspeed/utils/distributed.py'\n",
      "adding 'deepspeed/utils/exceptions.py'\n",
      "adding 'deepspeed/utils/groups.py'\n",
      "adding 'deepspeed/utils/logging.py'\n",
      "adding 'deepspeed/utils/nvtx.py'\n",
      "adding 'deepspeed/utils/timer.py'\n",
      "adding 'deepspeed/utils/zero_to_fp32.py'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/deepspeed'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/deepspeed.pt'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/ds'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/ds_elastic'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/ds_report'\n",
      "adding 'deepspeed-0.6.1+097efeb.data/scripts/ds_ssh'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/LICENSE'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/METADATA'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/WHEEL'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/entry_points.txt'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/top_level.txt'\n",
      "adding 'deepspeed-0.6.1+097efeb.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepspeed build time = 0.2972147464752197 secs\n",
      "Installing deepspeed\n",
      "Processing ./dist/deepspeed-0.6.1+097efeb-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (21.3)\n",
      "Requirement already satisfied: hjson in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (3.0.2)\n",
      "Requirement already satisfied: ninja in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.10.2.3)\n",
      "Requirement already satisfied: torch in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.10.2)\n",
      "Requirement already satisfied: psutil in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (5.9.0)\n",
      "Requirement already satisfied: numpy in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (4.63.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (8.0.0)\n",
      "Requirement already satisfied: triton==1.0.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from packaging->deepspeed==0.6.1+097efeb) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from torch->deepspeed==0.6.1+097efeb) (3.10.0.2)\n",
      "deepspeed is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages/torch']\n",
      "torch version .................... 1.10.2\n",
      "torch cuda version ............... 11.1\n",
      "torch hip version ................ None\n",
      "nvcc version ..................... 11.1\n",
      "deepspeed install path ........... ['/home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.6.1+097efeb, 097efeb, master\n",
      "deepspeed wheel compiled w. ...... torch 1.10, cuda 11.1, hip 0.0\n"
     ]
    }
   ],
   "source": [
    "#!ls\n",
    "\n",
    "!DS_CPU_ADAM=1 ./install.sh -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade7d343",
   "metadata": {},
   "source": [
    "## You should see above everything (or at least most of things) in the column 'compatiable' be hilighted with green \"OKAY\", if not, than sorry, something somewere must have messed up and now you are at the mercy of googlefu to find a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847239cb",
   "metadata": {},
   "source": [
    "## We are finally ready to install/build the DeepSpeed for the PPPds enviriment, this part will take between 15 to 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f853611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/user02/Desktop/PPPdeepspeed/DeepSpeed\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: hjson in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (3.0.2)\n",
      "Requirement already satisfied: ninja in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.10.2.3)\n",
      "Requirement already satisfied: numpy in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.21.2)\n",
      "Requirement already satisfied: packaging in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (21.3)\n",
      "Requirement already satisfied: psutil in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (8.0.0)\n",
      "Requirement already satisfied: torch in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.10.2)\n",
      "Requirement already satisfied: tqdm in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (4.63.0)\n",
      "Requirement already satisfied: triton==1.0.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from deepspeed==0.6.1+097efeb) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from packaging->deepspeed==0.6.1+097efeb) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from torch->deepspeed==0.6.1+097efeb) (3.10.0.2)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.6.1+097efeb-cp37-cp37m-linux_x86_64.whl size=35112203 sha256=1716f001bd791345756203ad61f66bce0c44a981cc1934d466cd0e9d2d05afe8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ie83lgjn/wheels/47/4f/64/ef3a4c6a50de659ab4b50f4c1829b081417017789688526254\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: deepspeed\n",
      "  Attempting uninstall: deepspeed\n",
      "    Found existing installation: deepspeed 0.6.1+097efeb\n",
      "    Uninstalling deepspeed-0.6.1+097efeb:\n",
      "      Successfully uninstalled deepspeed-0.6.1+097efeb\n",
      "Successfully installed deepspeed-0.6.1+097efeb\n"
     ]
    }
   ],
   "source": [
    "#if async_io acts like little shit use this\n",
    "##!DS_BUILD_AIO=0 DS_BUILD_OPS=1 pip install .\n",
    "\n",
    "\n",
    "!DS_BUILD_OPS=1 pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9fdcd",
   "metadata": {},
   "source": [
    "## We can now make sure that DeepSpeed is properly installed by running the snippet below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5c921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "cpu_adam ............... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lamb ............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "sparse_attn ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "async_io ............... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "utils .................. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer_inference .. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages/torch']\n",
      "torch version .................... 1.10.2\n",
      "torch cuda version ............... 11.1\n",
      "torch hip version ................ None\n",
      "nvcc version ..................... 11.1\n",
      "deepspeed install path ........... ['/home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.6.1+097efeb, 097efeb, master\n",
      "deepspeed wheel compiled w. ...... torch 1.10, cuda 11.1, hip 0.0\n"
     ]
    }
   ],
   "source": [
    "!ds_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f11ab6",
   "metadata": {},
   "source": [
    "# Next we need to download the repo that will be actually finetuning the GPT Neo model using DeepSpeed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c313c",
   "metadata": {},
   "source": [
    "## First we need to exit the DeepSpeed repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a244d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user02/Desktop/PPPdeepspeed\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab4bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpeed  GPT_Neo_Fine-tune.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd17a97",
   "metadata": {},
   "source": [
    "## Now we clone the finetuning repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a37c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'finetune-gpt2xl'...\n",
      "remote: Enumerating objects: 381, done.\u001b[K\n",
      "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 381 (delta 18), reused 12 (delta 5), pack-reused 304\u001b[K\n",
      "Receiving objects: 100% (381/381), 3.42 MiB | 4.68 MiB/s, done.\n",
      "Resolving deltas: 100% (237/237), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Xirider/finetune-gpt2xl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec84cb9",
   "metadata": {},
   "source": [
    "## Now we need enter the pulled repo \n",
    "## (Step 3 starts here, for runing custom data just ignore the 1st deepspeed running code and edit the last one )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d7f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpeed  finetune-gpt2xl  GPT_Neo_Fine-tune.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e7ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user02/Desktop/PPPdeepspeed/finetune-gpt2xl\n"
     ]
    }
   ],
   "source": [
    "%cd finetune-gpt2xl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67d015",
   "metadata": {},
   "source": [
    "## Lastly, we need to download the datasets library that this repo uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14162e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (1.18.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (4.8.2)\n",
      "Requirement already satisfied: pandas in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: multiprocess in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: xxhash in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: dill in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: packaging in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user02/anaconda3/envs/PPPds/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91547c7e",
   "metadata": {},
   "source": [
    "# At this point we are able to finetune GPT Neo(including 2.7B) and other GPT models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811f9a8",
   "metadata": {},
   "source": [
    "## For GPT NEO 2.7B parameters, we need a high end machine.  Roughly 70GB of RAM is the minimum required for it, along with roughly 16GB of VRAM. GPT Neo 1.3B and other smaller GPT2 models don't have as high of requirements. This can rented for an ok price from a cloud provider if you dont have a powerful enough machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89aec0",
   "metadata": {},
   "source": [
    "## Lets now finetune model with the provided Shakespeare dataset with the example flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b1af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-09 10:07:11,386] [WARNING] [runner.py:155:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2022-03-09 10:07:11,418] [INFO] [runner.py:438:main] cmd = /home/user02/anaconda3/envs/PPPds/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 run_clm.py --deepspeed ds_config_gptneo.json --model_name_or_path EleutherAI/gpt-neo-125M --train_file train.csv --validation_file validation.csv --do_train --do_eval --fp16 --overwrite_cache --evaluation_strategy=steps --output_dir finetunedTEST --num_train_epochs 1 --eval_steps 15 --gradient_accumulation_steps 2 --per_device_train_batch_size 4 --use_fast_tokenizer False --learning_rate 5e-06 --warmup_steps 10\n",
      "[2022-03-09 10:07:12,268] [INFO] [launch.py:103:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2022-03-09 10:07:12,268] [INFO] [launch.py:110:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2022-03-09 10:07:12,268] [INFO] [launch.py:122:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2022-03-09 10:07:12,268] [INFO] [launch.py:123:main] dist_world_size=1\n",
      "[2022-03-09 10:07:12,269] [INFO] [launch.py:125:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "[2022-03-09 10:07:15,516] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "03/09/2022 10:07:15 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "03/09/2022 10:07:15 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=ds_config_gptneo.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=15,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=finetunedTEST/runs/Mar09_10-07-15_user-02,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=finetunedTEST,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=finetunedTEST,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=10,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/09/2022 10:07:25 - WARNING - datasets.builder -   Using custom data configuration default-e4a137bb21322957\n",
      "Downloading and preparing dataset csv/default to /home/user02/.cache/huggingface/datasets/csv/default-e4a137bb21322957/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 7847.15it/s]\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1615.68it/s]\n",
      "Dataset csv downloaded and prepared to /home/user02/.cache/huggingface/datasets/csv/default-e4a137bb21322957/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 33.21it/s]\n",
      "[INFO|configuration_utils.py:648] 2022-03-09 10:07:26,622 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /home/user02/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "[INFO|configuration_utils.py:684] 2022-03-09 10:07:26,624 >> Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:648] 2022-03-09 10:07:27,499 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /home/user02/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "[INFO|configuration_utils.py:684] 2022-03-09 10:07:27,500 >> Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-03-09 10:07:29,681 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at /home/user02/.cache/huggingface/transformers/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-03-09 10:07:29,681 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at /home/user02/.cache/huggingface/transformers/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-03-09 10:07:29,681 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-03-09 10:07:29,681 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at /home/user02/.cache/huggingface/transformers/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-03-09 10:07:29,681 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at /home/user02/.cache/huggingface/transformers/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:648] 2022-03-09 10:07:30,141 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /home/user02/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "[INFO|configuration_utils.py:684] 2022-03-09 10:07:30,142 >> Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1431] 2022-03-09 10:07:30,792 >> loading weights file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin from cache at /home/user02/.cache/huggingface/transformers/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
      "[INFO|modeling_utils.py:1702] 2022-03-09 10:07:38,586 >> All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:1711] 2022-03-09 10:07:38,586 >> All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-125M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
      "  0%|                                                     | 0/1 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:3398] 2022-03-09 10:07:45,941 >> Token indices sequence length is longer than the specified maximum sequence length for this model (1462828 > 2048). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.87s/ba]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 40.91ba/s]\n",
      "run_clm.py:361: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
      "03/09/2022 10:07:47 - WARNING - __main__ -   The tokenizer picked seems to have a very large `model_max_length` (2048). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/ba]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 188.11ba/s]\n",
      "[INFO|trainer.py:457] 2022-03-09 10:07:48,497 >> Using amp half precision backend\n",
      "[2022-03-09 10:07:48,499] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.6.1+097efeb, git-hash=097efeb, git-branch=master\n",
      "[2022-03-09 10:07:49,900] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000005, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2022-03-09 10:07:50,318] [INFO] [engine.py:1066:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2022-03-09 10:07:50,322] [INFO] [engine.py:1073:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2022-03-09 10:07:50,322] [INFO] [utils.py:49:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2022-03-09 10:07:50,322] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
      "[2022-03-09 10:07:50,322] [INFO] [stage_1_and_2.py:125:__init__] Reduce bucket size 200000000.0\n",
      "[2022-03-09 10:07:50,322] [INFO] [stage_1_and_2.py:126:__init__] Allgather bucket size 200000000.0\n",
      "[2022-03-09 10:07:50,322] [INFO] [stage_1_and_2.py:127:__init__] CPU Offload: True\n",
      "[2022-03-09 10:07:50,322] [INFO] [stage_1_and_2.py:128:__init__] Round robin gradient partitioning: False\n",
      "Rank: 0 partition count [1] and sizes[(125198592, False)] \n",
      "[2022-03-09 10:07:50,716] [INFO] [utils.py:824:see_memory_usage] Before initializing optimizer states\n",
      "[2022-03-09 10:07:50,717] [INFO] [utils.py:829:see_memory_usage] MA 0.35 GB         Max_MA 0.35 GB         CA 0.52 GB         Max_CA 1 GB \n",
      "[2022-03-09 10:07:50,717] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 11.07 GB, percent = 35.4%\n",
      "[2022-03-09 10:07:51,160] [INFO] [utils.py:824:see_memory_usage] After initializing optimizer states\n",
      "[2022-03-09 10:07:51,161] [INFO] [utils.py:829:see_memory_usage] MA 0.35 GB         Max_MA 0.35 GB         CA 0.52 GB         Max_CA 1 GB \n",
      "[2022-03-09 10:07:51,161] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 12.48 GB, percent = 39.9%\n",
      "[2022-03-09 10:07:51,161] [INFO] [stage_1_and_2.py:497:__init__] optimizer state initialized\n",
      "[2022-03-09 10:07:51,195] [INFO] [utils.py:824:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2022-03-09 10:07:51,195] [INFO] [utils.py:829:see_memory_usage] MA 0.35 GB         Max_MA 0.35 GB         CA 0.52 GB         Max_CA 1 GB \n",
      "[2022-03-09 10:07:51,195] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 12.48 GB, percent = 39.9%\n",
      "[2022-03-09 10:07:51,195] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2022-03-09 10:07:51,195] [INFO] [engine.py:777:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2022-03-09 10:07:51,196] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f6b344dfad0>\n",
      "[2022-03-09 10:07:51,196] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-06], mom=[[0.9, 0.999]]\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1058:print] DeepSpeedEngine configuration:\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   amp_enabled .................. False\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   amp_params ................... False\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": null, \n",
      "    \"exps_dir\": null, \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   bfloat16_enabled ............. False\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   checkpoint_tag_validation_enabled  True\n",
      "[2022-03-09 10:07:51,196] [INFO] [config.py:1062:print]   checkpoint_tag_validation_fail  False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   communication_data_type ...... None\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   curriculum_enabled ........... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   curriculum_params ............ False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   dataloader_drop_last ......... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   disable_allgather ............ False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   dump_state ................... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_enabled ........... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_layer_num ......... 0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_max_iter .......... 100\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_stability ......... 1e-06\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_tol ............... 0.01\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   eigenvalue_verbose ........... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   elasticity_enabled ........... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   fp16_enabled ................. True\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   fp16_master_weights_and_gradients  False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   fp16_mixed_quantize .......... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   global_rank .................. 0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   gradient_accumulation_steps .. 2\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   gradient_clipping ............ 1.0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   gradient_predivide_factor .... 1.0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   initial_dynamic_scale ........ 65536\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   loss_scale ................... 0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   memory_breakdown ............. False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   optimizer_legacy_fusion ...... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   optimizer_name ............... adamw\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   optimizer_params ............. {'lr': 5e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   pld_enabled .................. False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   pld_params ................... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   prescale_gradients ........... False\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_change_rate ......... 0.001\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_groups .............. 1\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_offset .............. 1000\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_period .............. 1000\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_rounding ............ 0\n",
      "[2022-03-09 10:07:51,197] [INFO] [config.py:1062:print]   quantize_start_bits .......... 16\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   quantize_target_bits ......... 8\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   quantize_training_enabled .... False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   quantize_type ................ 0\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   quantize_verbose ............. False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   scheduler_name ............... WarmupLR\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-06, 'warmup_num_steps': 10}\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   sparse_attention ............. None\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   sparse_gradients_enabled ..... False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   steps_per_print .............. 2000\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   tensorboard_enabled .......... False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   tensorboard_output_path ...... \n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   train_batch_size ............. 8\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   train_micro_batch_size_per_gpu  4\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   use_quantizer_kernel ......... False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   wall_clock_breakdown ......... False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   world_size ................... 1\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   zero_allow_untested_optimizer  False\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   zero_config .................. {\n",
      "    \"stage\": 2, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 2.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 2.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": false, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": null, \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": false, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_16bit_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   zero_enabled ................. True\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1062:print]   zero_optimization_stage ...... 2\n",
      "[2022-03-09 10:07:51,198] [INFO] [config.py:1070:print]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-06, \n",
      "            \"warmup_num_steps\": 10\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"cpu_offload\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 8, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "[INFO|trainer.py:1279] 2022-03-09 10:07:51,198 >> ***** Running training *****\n",
      "[INFO|trainer.py:1280] 2022-03-09 10:07:51,198 >>   Num examples = 1428\n",
      "[INFO|trainer.py:1281] 2022-03-09 10:07:51,198 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1282] 2022-03-09 10:07:51,198 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1283] 2022-03-09 10:07:51,199 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1284] 2022-03-09 10:07:51,199 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1285] 2022-03-09 10:07:51,199 >>   Total optimization steps = 178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|███▌                                      | 15/178 [00:43<07:51,  2.90s/it][INFO|trainer.py:2389] 2022-03-09 10:08:34,620 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:08:34,620 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:08:34,620 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.21875, 'eval_runtime': 0.3768, 'eval_samples_per_second': 10.615, 'eval_steps_per_second': 2.654, 'epoch': 0.08}\n",
      "  8%|███▌                                      | 15/178 [00:43<07:51,  2.90s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\n",
      " 17%|███████                                   | 30/178 [01:27<07:14,  2.94s/it][INFO|trainer.py:2389] 2022-03-09 10:09:18,796 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:09:18,796 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:09:18,796 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.2109375, 'eval_runtime': 0.3745, 'eval_samples_per_second': 10.682, 'eval_steps_per_second': 2.67, 'epoch': 0.17}\n",
      " 17%|███████                                   | 30/178 [01:27<07:14,  2.94s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.80it/s]\u001b[A\n",
      " 25%|██████████▌                               | 45/178 [02:11<06:28,  2.92s/it][INFO|trainer.py:2389] 2022-03-09 10:10:02,986 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:10:02,986 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:10:02,986 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.20703125, 'eval_runtime': 0.3742, 'eval_samples_per_second': 10.691, 'eval_steps_per_second': 2.673, 'epoch': 0.25}\n",
      " 25%|██████████▌                               | 45/178 [02:12<06:28,  2.92s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.82it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 60/178 [02:55<05:43,  2.91s/it][INFO|trainer.py:2389] 2022-03-09 10:10:47,172 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:10:47,172 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:10:47,172 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.203125, 'eval_runtime': 0.3784, 'eval_samples_per_second': 10.572, 'eval_steps_per_second': 2.643, 'epoch': 0.34}\n",
      " 34%|██████████████▏                           | 60/178 [02:56<05:43,  2.91s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 75/178 [03:40<05:01,  2.93s/it][INFO|trainer.py:2389] 2022-03-09 10:11:31,481 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:11:31,481 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:11:31,481 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.19921875, 'eval_runtime': 0.3802, 'eval_samples_per_second': 10.521, 'eval_steps_per_second': 2.63, 'epoch': 0.42}\n",
      " 42%|█████████████████▋                        | 75/178 [03:40<05:01,  2.93s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\u001b[A\n",
      " 51%|█████████████████████▏                    | 90/178 [04:24<04:18,  2.93s/it][INFO|trainer.py:2389] 2022-03-09 10:12:15,930 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:12:15,930 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:12:15,930 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.1953125, 'eval_runtime': 0.3717, 'eval_samples_per_second': 10.761, 'eval_steps_per_second': 2.69, 'epoch': 0.5}\n",
      " 51%|█████████████████████▏                    | 90/178 [04:25<04:18,  2.93s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\n",
      " 59%|████████████████████████▏                | 105/178 [05:08<03:33,  2.92s/it][INFO|trainer.py:2389] 2022-03-09 10:13:00,185 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:13:00,185 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:13:00,185 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.19140625, 'eval_runtime': 0.3759, 'eval_samples_per_second': 10.641, 'eval_steps_per_second': 2.66, 'epoch': 0.59}\n",
      " 59%|████████████████████████▏                | 105/178 [05:09<03:33,  2.92s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\u001b[A\n",
      " 67%|███████████████████████████▋             | 120/178 [05:53<02:52,  2.98s/it][INFO|trainer.py:2389] 2022-03-09 10:13:44,702 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:13:44,702 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:13:44,702 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.19140625, 'eval_runtime': 0.3832, 'eval_samples_per_second': 10.439, 'eval_steps_per_second': 2.61, 'epoch': 0.67}\n",
      " 67%|███████████████████████████▋             | 120/178 [05:53<02:52,  2.98s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 135/178 [06:37<02:05,  2.93s/it][INFO|trainer.py:2389] 2022-03-09 10:14:29,048 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:14:29,048 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:14:29,048 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.1875, 'eval_runtime': 0.3791, 'eval_samples_per_second': 10.551, 'eval_steps_per_second': 2.638, 'epoch': 0.76}\n",
      " 76%|███████████████████████████████          | 135/178 [06:38<02:05,  2.93s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 150/178 [07:23<01:28,  3.15s/it][INFO|trainer.py:2389] 2022-03-09 10:15:14,947 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:15:14,947 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:15:14,947 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.1875, 'eval_runtime': 0.4078, 'eval_samples_per_second': 9.809, 'eval_steps_per_second': 2.452, 'epoch': 0.84}\n",
      " 84%|██████████████████████████████████▌      | 150/178 [07:24<01:28,  3.15s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.55it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 165/178 [08:09<00:39,  3.02s/it][INFO|trainer.py:2389] 2022-03-09 10:16:01,146 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:16:01,146 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:16:01,146 >>   Batch size = 8\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.1875, 'eval_runtime': 0.3994, 'eval_samples_per_second': 10.015, 'eval_steps_per_second': 2.504, 'epoch': 0.92}\n",
      " 93%|██████████████████████████████████████   | 165/178 [08:10<00:39,  3.02s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.62it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 178/178 [08:48<00:00,  2.93s/it][INFO|trainer.py:1508] 2022-03-09 10:16:39,659 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 528.4604, 'train_samples_per_second': 2.702, 'train_steps_per_second': 0.337, 'train_loss': 3.6097096646769664, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████| 178/178 [08:48<00:00,  2.97s/it]\n",
      "[INFO|trainer.py:2139] 2022-03-09 10:16:39,660 >> Saving model checkpoint to finetunedTEST\n",
      "[INFO|configuration_utils.py:439] 2022-03-09 10:16:39,660 >> Configuration saved in finetunedTEST/config.json\n",
      "[INFO|modeling_utils.py:1084] 2022-03-09 10:16:40,069 >> Model weights saved in finetunedTEST/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2094] 2022-03-09 10:16:40,069 >> tokenizer config file saved in finetunedTEST/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2100] 2022-03-09 10:16:40,069 >> Special tokens file saved in finetunedTEST/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     3.6097\n",
      "  train_runtime            = 0:08:48.46\n",
      "  train_samples            =       1428\n",
      "  train_samples_per_second =      2.702\n",
      "  train_steps_per_second   =      0.337\n",
      "03/09/2022 10:16:40 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:2389] 2022-03-09 10:16:40,146 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2391] 2022-03-09 10:16:40,146 >>   Num examples = 4\n",
      "[INFO|trainer.py:2394] 2022-03-09 10:16:40,146 >>   Batch size = 8\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     4.1836\n",
      "  eval_runtime            = 0:00:00.37\n",
      "  eval_samples            =          4\n",
      "  eval_samples_per_second =     10.637\n",
      "  eval_steps_per_second   =      2.659\n",
      "  perplexity              =    65.6012\n",
      "[2022-03-09 10:16:41,855] [INFO] [launch.py:210:main] Process 119045 exits successfully.\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=1 run_clm.py \\\n",
    "--deepspeed ds_config_gptneo.json \\\n",
    "--model_name_or_path EleutherAI/gpt-neo-125M \\\n",
    "--train_file train.csv \\\n",
    "--validation_file validation.csv \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--fp16 \\\n",
    "--overwrite_cache \\\n",
    "--evaluation_strategy=\"steps\" \\\n",
    "--output_dir finetunedTEST \\\n",
    "--num_train_epochs 1 \\\n",
    "--eval_steps 15 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--per_device_train_batch_size 4 \\\n",
    "--use_fast_tokenizer False \\\n",
    "--learning_rate 5e-06 \\\n",
    "--warmup_steps 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38bbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the above test run correcly you can now take steps into using your own datasets (do make sure it's written and save correcly) in the Desktop/PPPds/finetune-gpt2xl folder. \n",
    "## Custom deepspeed, just rename the folder and the training/validation (those two CAN be the same text file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13529c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--train_file YOURFILE.txt \\\n",
    "#--validation_file YOURFILE.txt \\\n",
    "#--output_dir YOURFOLDER \\\n",
    "\n",
    "#EleutherAI GPT Neo models list avaiable on huggingface https://huggingface.co/EleutherAI\n",
    "#EleutherAI/gpt-neo-125M\n",
    "#EleutherAI/gpt-neo-1.3B\n",
    "#EleutherAI/gpt-neo-2.7B\n",
    "#EleutherAI/gpt-j-6B\n",
    "\n",
    "#--model_name_or_path EleutherAI/gpt-neo-125M \\\n",
    "\n",
    "!deepspeed --num_gpus=1 run_clm.py \\\n",
    "--deepspeed ds_config_gptneo.json \\\n",
    "--model_name_or_path EleutherAI/gpt-neo-125M \\\n",
    "--train_file fimfic.txt \\\n",
    "--validation_file fimfic.txt \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--fp16 \\\n",
    "--overwrite_cache \\\n",
    "--evaluation_strategy=\"steps\" \\\n",
    "--output_dir finetuned \\\n",
    "--num_train_epochs 1 \\\n",
    "--eval_steps 15 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--per_device_train_batch_size 4 \\\n",
    "--use_fast_tokenizer False \\\n",
    "--learning_rate 5e-06 \\\n",
    "--warmup_steps 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PPPds",
   "language": "python",
   "name": "pppds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
